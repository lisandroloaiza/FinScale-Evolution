# Patrones y T√°cticas de Arquitectura

> **Objetivo**: Justificar decisiones de patrones con base en drivers  
> **Metodolog√≠a**: WhyDD - vincular **WHY** (driver) ‚Üí **WHAT** (patr√≥n) ‚Üí **HOW** (implementaci√≥n)

---

## üéØ Estilos Arquitect√≥nicos Seleccionados

### 1. Microservicios

**WHY** (Drivers relacionados):
- **Desaf√≠o de Negocio**: El sistema actual es un monolito J2EE con una clase TransactionManager.java de 15,000 l√≠neas que acopla m√∫ltiples responsabilidades (Pagos, Fraude, Clientes, Notificaciones), generando un Time-to-Market de 4 meses y limitando la capacidad de innovaci√≥n
- **Escalabilidad Diferenciada**: Necesidad de escalar servicios de forma independiente seg√∫n demanda (Payment Service requiere 12 r√©plicas vs. FX Service solo 3)
- **Agilidad Organizacional**: Habilitar equipos aut√≥nomos que desplieguen sin coordinaci√≥n central ‚Üí reducir Time-to-Market a 2 semanas
- **Modernizaci√≥n sin Interrupci√≥n**: Migrar incrementalmente desde arquitectura monol√≠tica sin detener operaci√≥n 24/7

**WHAT** (Caracter√≠sticas):
- **10 servicios core**: Payment, Ledger, Fraud, FX, Clearing, Reconciliation, Legacy Facade, HSM Proxy, CDC Adapter, Temporal
- **Database per Service**: PostgreSQL (Payment, Fraud), TimescaleDB (Ledger), Cassandra (FX), Redis (Cache)
- **Comunicaci√≥n h√≠brida**: REST sync + Kafka async + gRPC para HSM

**HOW** (Implementaci√≥n):
```yaml
Governance:
  - API Gateway centralizado (Kong)
  - Service Mesh (Istio) para observabilidad
  - Contratos con OpenAPI 3.0
  
Deployment:
  - Kubernetes con Helm charts
  - CI/CD independiente por servicio
  - Feature flags para releases graduales
```

**Trade-offs**:
- ‚úÖ Ventajas: Escalabilidad granular, resiliencia por aislamiento
- ‚ùå Desventajas: Complejidad operacional, consistencia eventual

---

### 2. Event-Driven Architecture (EDA)

**WHY**:
- **Resiliencia**: Desacoplamiento temporal (servicios pueden estar ca√≠dos)
- **Disponibilidad**: Procesamiento as√≠ncrono de picos de carga
- **Compliance**: Auditor√≠a completa v√≠a eventos inmutables

**WHAT**:
- Apache Kafka como event bus
- Event Sourcing en Ledger Service
- CQRS en Payment y Fraud Services

**HOW**:
```java
// Publicaci√≥n de eventos
@Component
public class PaymentEventPublisher {
    
    private final ReactiveKafkaProducerTemplate<String, DomainEvent> kafka;
    
    public Mono<Void> publishPaymentExecuted(PaymentOrder payment) {
        var event = new PaymentExecuted(
            payment.getId(),
            payment.getAmount(),
            payment.getBeneficiary(),
            Instant.now()
        );
        
        return kafka.send("payment-events", payment.getId(), event)
            .then();
    }
}

// Consumo con garant√≠a de orden
@KafkaListener(topics = "payment-events", groupId = "ledger-group")
public void handlePaymentExecuted(PaymentExecuted event) {
    // Kafka garantiza orden por partici√≥n (clave = paymentId)
    ledgerService.createEntry(event);
}
```

**Trade-offs**:
- ‚úÖ Ventajas: Alta disponibilidad, escalabilidad horizontal
- ‚ùå Desventajas: Eventual consistency, debugging complejo

---

## üèóÔ∏è Patrones T√°cticos Seleccionados

### Patr√≥n 1: Strangler Fig (Migraci√≥n Legacy)

**WHY** (Contexto del Sistema Legacy):
- **Disponibilidad Cr√≠tica**: Sistema monol√≠tico J2EE + Oracle que procesa 8.5M transacciones/mes en operaci√≥n continua 24/7, sin ventanas de mantenimiento disponibles
- **Mitigaci√≥n de Riesgo**: Las migraciones tipo "Big Bang" tienen alta tasa de fallo seg√∫n industria, poniendo en riesgo la continuidad operacional del negocio
- **Cumplimiento Regulatorio**: Marco normativo financiero proh√≠be p√©rdida de transacciones durante procesos de modernizaci√≥n (PCI-DSS, GDPR)

**WHAT**:
- Patr√≥n de Martin Fowler para migraci√≥n incremental
- Nueva funcionalidad ‚Üí Sistema Nuevo
- Funcionalidad Legacy ‚Üí Redirigir progresivamente
- Legacy "estrangulado" hasta desconexi√≥n final

**HOW** (3 Fases):

#### Fase 1: Coexistencia (10% tr√°fico nuevo)

```mermaid
flowchart LR
    Cliente([Cliente<br/>Mobile/Web]) --> Gateway{API Gateway<br/>Kong}
    
    Gateway -->|90% tr√°fico| Legacy[Legacy J2EE<br/>Monolito]
    Gateway -->|10% tr√°fico| Payment[Payment Service<br/>Nuevo Sistema]
    
    Payment --> CDC[CDC Adapter<br/>Debezium]
    CDC -->|Sincroniza<br/>datos| Legacy
    
    Legacy --> Oracle[(Oracle DB)]
    Payment --> Postgres[(PostgreSQL)]
    
    style Gateway fill:#4a90e2,color:#fff
    style Payment fill:#7ed321,color:#fff
    style Legacy fill:#f5a623,color:#fff
    style CDC fill:#bd10e0,color:#fff
```

**Timeline**: Mes 1-3  
**Objetivo**: Validar CDC bidireccional sin errores  
**Rollback**: Cambiar configuraci√≥n de Gateway a 0% tr√°fico nuevo

---

#### Fase 2: Migraci√≥n Activa (70% tr√°fico nuevo)

```mermaid
flowchart LR
    Cliente([Cliente<br/>Mobile/Web]) --> Gateway{API Gateway<br/>Kong}
    
    Gateway -->|30% tr√°fico| Legacy[Legacy J2EE<br/>Reduciendo]
    Gateway -->|70% tr√°fico| Payment[Payment Service<br/>Sistema Principal]
    
    Payment <--> CDC[CDC Adapter<br/>Bidireccional]
    CDC <--> Legacy
    
    Legacy --> Oracle[(Oracle DB)]
    Payment --> Postgres[(PostgreSQL)]
    
    Payment --> Kafka[Kafka<br/>Event Bus]
    Payment --> Fraud[Fraud Service]
    Payment --> FX[FX Service]
    
    style Gateway fill:#4a90e2,color:#fff
    style Payment fill:#7ed321,color:#fff
    style Legacy fill:#f5a623,color:#fff
    style CDC fill:#bd10e0,color:#fff
    style Kafka fill:#50e3c2,color:#000
```

**Timeline**: Mes 4-9  
**Objetivo**: Latencia p99 < 200ms, 0 discrepancias en reconciliaci√≥n  
**Riesgo**: Mayor carga en CDC, monitoreo intensivo

---

#### Fase 3: Desmantelamiento (100% tr√°fico nuevo)

```mermaid
flowchart LR
    Cliente([Cliente<br/>Mobile/Web]) --> Gateway{API Gateway<br/>Kong}
    
    Gateway -->|100% tr√°fico| Payment[Payment Service<br/>Sistema √önico]
    
    Legacy[Legacy J2EE<br/>üóëÔ∏è APAGADO]
    
    Payment --> Postgres[(PostgreSQL)]
    Payment --> Kafka[Kafka<br/>Event Bus]
    Payment --> Fraud[Fraud Service]
    Payment --> FX[FX Service]
    Payment --> Ledger[Ledger Service]
    Payment --> Clearing[Clearing Service]
    
    style Gateway fill:#4a90e2,color:#fff
    style Payment fill:#7ed321,color:#fff
    style Legacy fill:#ff6b6b,color:#fff
    style Kafka fill:#50e3c2,color:#000
```

**Timeline**: Mes 10-12  
**Objetivo**: Apagar infraestructura Legacy completa  
**Validaci√≥n**: 30 d√≠as de operaci√≥n estable antes de desconectar Oracle

```yaml
# Configuraci√≥n de API Gateway (Kong)
services:
  - name: payment-service
    url: http://payment-service:8080
    routes:
      - name: payment-route
        paths:
          - /api/v1/payments
        plugins:
          - name: traffic-split
            config:
              # Fase 1: 10% nuevo, 90% legacy
              splits:
                - weight: 10
                  upstream_url: http://payment-service:8080
                - weight: 90
                  upstream_url: http://legacy-j2ee:7001
```

**Validaci√≥n Medible**:
- Fase 1 (Mes 1-3): 10% tr√°fico ‚Üí 0 errores de sincronizaci√≥n CDC
- Fase 2 (Mes 4-9): 70% tr√°fico ‚Üí Latencia p99 < 200ms
- Fase 3 (Mes 10-12): 100% tr√°fico ‚Üí Apagar Legacy

**Trade-offs**:
- ‚úÖ Migraci√≥n sin downtime
- ‚úÖ Rollback instant√°neo (cambiar % en Gateway)
- ‚ùå Complejidad temporal (CDC bidireccional)
- ‚ùå Datos duplicados durante migraci√≥n

---

### Patr√≥n 2: Anti-Corruption Layer (ACL)

**WHY** (Problem√°tica del Sistema Actual):
- **Deuda T√©cnica de Modelos**: Sistema Legacy utiliza entidades an√©micas (Account.java con 200+ campos) que violan principios de cohesi√≥n, mientras que la arquitectura propuesta implementa Domain-Driven Design con bounded contexts especializados
- **Preservaci√≥n de Calidad Arquitect√≥nica**: Prevenir que patrones anti-patr√≥n del sistema Legacy contaminen la nueva arquitectura cloud-native

**WHAT**:
- Servicio traductor: **Legacy Facade**
- Traduce entre modelo Legacy (an√©mico) y modelo Nuevo (DDD rich domain)
- √önico punto de contacto Legacy‚ÜîNuevo

**HOW**:

```java
// Legacy Facade como ACL
@Service
public class LegacyFacade {
    
    private final LegacySystemClient legacyClient;  // SOAP/XML
    
    // Traducir del mundo Legacy al mundo Nuevo
    public PaymentOrder fromLegacy(LegacyTransaction legacyTx) {
        return PaymentOrder.builder()
            .id(PaymentOrderId.of(legacyTx.getTxId()))
            .amount(Money.of(
                legacyTx.getAmount(),
                Currency.valueOf(legacyTx.getCurrencyCode())
            ))
            .originator(AccountId.of(legacyTx.getDebitAccount()))
            .beneficiary(AccountId.of(legacyTx.getCreditAccount()))
            .status(mapStatus(legacyTx.getStatus()))  // "P" ‚Üí PENDING
            .build();
    }
    
    // Traducir del mundo Nuevo al mundo Legacy
    public LegacyTransaction toLegacy(PaymentOrder payment) {
        LegacyTransaction tx = new LegacyTransaction();
        tx.setTxId(payment.getId().getValue());
        tx.setAmount(payment.getAmount().getValue());
        tx.setCurrencyCode(payment.getAmount().getCurrency().name());
        tx.setDebitAccount(payment.getOriginator().getValue());
        tx.setCreditAccount(payment.getBeneficiary().getValue());
        tx.setStatus(mapStatusToLegacy(payment.getStatus()));  // PENDING ‚Üí "P"
        tx.setCreatedDate(Date.from(payment.getCreatedAt()));  // Instant ‚Üí Date
        return tx;
    }
    
    private PaymentStatus mapStatus(String legacyStatus) {
        return switch(legacyStatus) {
            case "P" -> PaymentStatus.PENDING;
            case "A" -> PaymentStatus.APPROVED;
            case "R" -> PaymentStatus.REJECTED;
            case "S" -> PaymentStatus.SETTLED;
            default -> throw new IllegalStateException("Unknown status: " + legacyStatus);
        };
    }
}
```

**Beneficios Medibles**:
- **Aislamiento**: 0% de clases Legacy importadas en servicios nuevos
- **Testabilidad**: Mock Legacy Facade ‚Üí tests sin base Legacy
- **Time-to-Market**: Nuevos features no requieren entender Legacy

---

### Patr√≥n 3: CDC (Change Data Capture)

**WHY** (Desaf√≠o de Sincronizaci√≥n):
- **Consistencia Durante Coexistencia**: Durante la fase de migraci√≥n incremental (Strangler Fig), ambos sistemas (Legacy y Nuevo) deben mantener consistencia de datos en tiempo real para garantizar experiencia de usuario uniforme
- **Integridad Transaccional**: El patr√≥n dual-write (escritura simult√°nea en 2 sistemas) introduce riesgos de inconsistencia ante fallos parciales, violando garant√≠as ACID requeridas por el negocio

**WHAT**:
- **Debezium** captura cambios en Oracle (Legacy) ‚Üí publica a Kafka
- **CDC Adapter** escucha Kafka ‚Üí actualiza PostgreSQL (Nuevo)
- **Legacy Facade** publica cambios del Nuevo ‚Üí Legacy recibe v√≠a Kafka

**HOW**:

```mermaid
sequenceDiagram
    participant Legacy as Legacy DB<br/>(Oracle)
    participant Debezium as Debezium<br/>Connector
    participant Kafka
    participant CDC as CDC Adapter
    participant NewDB as New DB<br/>(PostgreSQL)
    participant Payment as Payment Service
    participant Facade as Legacy Facade
    
    Note over Legacy,NewDB: Flujo 1: Legacy ‚Üí Nuevo
    Legacy->>Legacy: UPDATE accounts<br/>SET balance = 1000
    Legacy->>Debezium: Oracle Redo Log
    Debezium->>Kafka: Publish AccountUpdated<br/>{id, balance, timestamp}
    Kafka->>CDC: Consume event
    CDC->>CDC: Transform schema<br/>Oracle ‚Üí PostgreSQL
    CDC->>NewDB: UPDATE accounts
    
    Note over Payment,Legacy: Flujo 2: Nuevo ‚Üí Legacy
    Payment->>NewDB: UPDATE accounts
    Payment->>Kafka: Publish AccountUpdated
    Kafka->>Facade: Consume event
    Facade->>Facade: Transform to Legacy model
    Facade->>Legacy: SOAP UpdateAccount()
```

```yaml
# Debezium Connector para Oracle
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: legacy-oracle-connector
spec:
  class: io.debezium.connector.oracle.OracleConnector
  tasksMax: 3
  config:
    database.hostname: legacy-oracle.internal
    database.port: 1521
    database.user: debezium
    database.dbname: FINSCALE
    database.server.name: legacy
    table.include.list: FINSCALE.ACCOUNTS,FINSCALE.TRANSACTIONS
    database.history.kafka.bootstrap.servers: kafka:9092
    database.history.kafka.topic: schema-changes.legacy
    # Capturar usando Oracle LogMiner
    log.mining.strategy: online_catalog
    log.mining.continuous.mine: true
```

**Validaci√≥n Medible**:
- **Latencia de sincronizaci√≥n**: < 2 segundos (p99)
- **Consistency**: 0 discrepancias detectadas en reconciliaci√≥n diaria
- **Throughput**: 1000 eventos/segundo

---

### Patr√≥n 4: CQRS (Command Query Responsibility Segregation)

**WHY**:
- **Escalabilidad**: Queries (90% del tr√°fico) escalan independiente de Commands
- **Performance**: Read models optimizados (Elasticsearch)

**WHAT**:
- Comandos ‚Üí PostgreSQL (escritura)
- Queries ‚Üí Elasticsearch (lectura)
- Sincronizaci√≥n v√≠a Kafka

**HOW**:

```java
// Command Side (Payment Service)
@PostMapping("/api/v1/payments")
public Mono<PaymentResponse> createPayment(@RequestBody CreatePaymentCmd cmd) {
    return commandHandler.handle(cmd)  // Escribe en PostgreSQL
        .doOnNext(payment -> 
            eventPublisher.publish(new PaymentCreated(payment))
        );
}

// Query Side (Search Service)
@KafkaListener(topics = "payment-events")
public void updateReadModel(PaymentCreated event) {
    // Proyectar a Elasticsearch
    PaymentDocument doc = PaymentDocument.from(event);
    elasticsearchRepository.save(doc);
}

@GetMapping("/api/v1/payments/search")
public Flux<PaymentDocument> search(@RequestParam String query) {
    return elasticsearchRepository.search(query);  // Lee de Elasticsearch
}
```

**M√©tricas de Validaci√≥n**:
- Write latency (PostgreSQL): p99 < 100ms
- Read latency (Elasticsearch): p99 < 50ms
- Eventual consistency lag: < 1 segundo

---

### Patr√≥n 2: Event Sourcing

**WHY**:
- **Compliance**: Regulaci√≥n exige auditor√≠a completa e inmutable
- **Debugging**: Reproducir estado hist√≥rico de cualquier cuenta

**WHAT**:
- Ledger Service almacena **eventos** en lugar de estado actual
- Estado se reconstruye reproduciendo eventos

**HOW**:

```java
// Aggregate con Event Sourcing
public class Account {
    private AccountId id;
    private Money balance;
    private List<LedgerEvent> uncommittedEvents = new ArrayList<>();
    
    // Aplicar comando
    public void debit(Money amount) {
        // Validar invariante
        if (balance.isLessThan(amount)) {
            throw new InsufficientFundsException();
        }
        
        // Generar evento
        var event = new FundsDebited(id, amount, Instant.now());
        apply(event);
        uncommittedEvents.add(event);
    }
    
    // Aplicar evento (idempotente)
    private void apply(FundsDebited event) {
        this.balance = this.balance.subtract(event.getAmount());
    }
    
    // Reconstruir desde eventos
    public static Account fromHistory(List<LedgerEvent> events) {
        Account account = new Account();
        events.forEach(account::apply);
        return account;
    }
}

// Repository con Event Store
@Repository
public class EventSourcedAccountRepository {
    
    public Mono<Void> save(Account account) {
        return Flux.fromIterable(account.getUncommittedEvents())
            .flatMap(event -> kafkaTemplate.send("ledger-events", event))
            .then();
    }
    
    public Mono<Account> findById(AccountId id) {
        return kafkaTemplate
            .receive("ledger-events")  // Leer desde Kafka compactado
            .filter(record -> record.getKey().equals(id))
            .collectList()
            .map(Account::fromHistory);
    }
}
```

**Beneficios Medibles**:
- 100% de auditor√≠a (vs. 70% con audit tables)
- Time-travel queries (reconstruir saldo a cualquier fecha)
- Debugging: Reproducir bug con eventos hist√≥ricos

---

### Patr√≥n 5: Saga Pattern con Temporal.io (Orquestaci√≥n)

**WHY** (Drivers de Arquitectura):
- **Orquestaci√≥n de Flujos Complejos**: Un pago internacional involucra coordinaci√≥n de 5 servicios especializados (Fraud Detection, FX Locking, Ledger, Clearing Network, Notification), requiriendo gesti√≥n centralizada del flujo
- **Eliminaci√≥n de Bloqueos Distribuidos**: Sistema actual utiliza XA transactions (2PC) que bloquean recursos hasta 30 segundos, creando cuellos de botella en horas pico
- **Recuperaci√≥n Autom√°tica ante Fallos**: Si red de clearing (SWIFT/PIX) rechaza transacci√≥n, el sistema debe revertir d√©bitos autom√°ticamente sin intervenci√≥n manual (actualmente es proceso manual de 6 horas)

**WHAT**:
- **Temporal.io** como orquestador durable (sobrevive a crashes)
- Workflow = estado + l√≥gica de compensaci√≥n
- Activities = llamadas a servicios externos

**HOW** (seg√∫n implementaci√≥n en Integracion.md):

```java
// Temporal Workflow
@WorkflowInterface
public interface PaymentWorkflow {
    @WorkflowMethod
    PaymentResult executePayment(PaymentOrder order);
}

@WorkflowImpl
public class PaymentWorkflowImpl implements PaymentWorkflow {
    
    private final FraudActivity fraudActivity = Workflow.newActivityStub(
        FraudActivity.class,
        ActivityOptions.newBuilder()
            .setStartToCloseTimeout(Duration.ofSeconds(5))
            .setRetryOptions(RetryOptions.newBuilder()
                .setMaximumAttempts(3)
                .build())
            .build()
    );
    
    @Override
    public PaymentResult executePayment(PaymentOrder order) {
        // Saga compensable
        Saga saga = new Saga(new Saga.Options.Builder()
            .setParallelCompensation(false)  // Compensar en orden inverso
            .build());
        
        try {
            // Paso 1: Validar fraude
            RiskScore riskScore = saga.addCompensation(
                () -> fraudActivity.score(order),
                () -> fraudActivity.releaseScore(order)  // Compensaci√≥n
            );
            
            if (riskScore.isBlocked()) {
                throw new FraudBlockedException(riskScore);
            }
            
            // Paso 2: Lock FX rate
            FXLock fxLock = saga.addCompensation(
                () -> fxActivity.lockRate(order),
                () -> fxActivity.releaseRate(fxLock)  // Compensaci√≥n
            );
            
            // Paso 3: Debitar cuenta
            LedgerEntry debit = saga.addCompensation(
                () -> ledgerActivity.debit(order),
                () -> ledgerActivity.credit(order)  // REVERSAL
            );
            
            // Paso 4: Enviar a clearing
            ClearingResult clearing = saga.addCompensation(
                () -> clearingActivity.send(order, fxLock),
                () -> clearingActivity.cancel(clearing)  // Compensaci√≥n
            );
            
            return PaymentResult.success(clearing);
            
        } catch (Exception e) {
            // Temporal ejecuta compensaciones autom√°ticamente
            saga.compensate();
            return PaymentResult.failed(e);
        }
    }
}

@Service
public class PaymentOrchestrator {
    
    public Mono<PaymentResult> executePayment(PaymentOrder payment) {
        return Mono.just(payment)
            // Paso 1: Validar fraude
            .flatMap(p -> fraudService.validate(p)
                .doOnError(e -> compensateFraud(p))
            )
            // Paso 2: Lock FX
            .flatMap(p -> fxService.lockRate(p)
                .doOnError(e -> compensateFX(p))
            )
            // Paso 3: Debitar cuenta
            .flatMap(p -> ledgerService.debit(p)
                .doOnError(e -> compensateLedger(p))
            )
            // Paso 4: Enviar a clearing
            .flatMap(p -> clearingService.send(p)
                .doOnError(e -> compensateClearing(p))
            )
            .onErrorResume(e -> {
                // Compensaci√≥n global
                compensateAll(payment);
                return Mono.error(new PaymentFailedException(e));
            });
    }
    
    private void compensateLedger(PaymentOrder payment) {
        // Reversar d√©bito
        ledgerService.credit(payment.getAmount(), "REVERSAL");
    }
}
```

**Alternativa Evaluada (y Descartada)**:
- **Choreography Saga**: Cada servicio reacciona a eventos
- **Raz√≥n del descarte**: Dificulta debugging (no hay vista centralizada del flujo)

---

### Patr√≥n 6: Circuit Breaker

**WHY** (Limitaciones del Sistema Actual):
- **Fallos en Cascada**: Sistema Legacy configura timeouts de 60 segundos que bloquean threads durante fallos de dependencias, provocando colapso total del servicio
- **Criticidad del Negocio**: Una ca√≠da del motor de ML para detecci√≥n de fraude NO debe detener completamente el procesamiento de pagos (actualmente detiene TODO el sistema)
- **Degradaci√≥n Controlada**: Implementar estrategia fail-fast con fallback autom√°tico a motor de reglas b√°sicas, permitiendo continuar operaci√≥n con capacidad reducida durante incidentes

**WHAT**:
- Estados: CLOSED ‚Üí OPEN ‚Üí HALF_OPEN
- Configuraci√≥n por servicio seg√∫n SLA

**HOW**:

```java
// Configuraci√≥n con Resilience4j
@Configuration
public class CircuitBreakerConfig {
    
    @Bean
    public CircuitBreaker fraudServiceCircuitBreaker() {
        return CircuitBreaker.of("fraud-service", CircuitBreakerConfig.custom()
            .failureRateThreshold(50)           // Abrir si 50% fallan
            .waitDurationInOpenState(Duration.ofSeconds(30))
            .permittedNumberOfCallsInHalfOpenState(5)
            .slidingWindowSize(10)
            .build()
        );
    }
}

// Uso con fallback
@Service
public class FraudClientWithCircuitBreaker {
    
    private final CircuitBreaker circuitBreaker;
    private final FraudServiceClient client;
    
    public Mono<RiskScore> score(PaymentOrder payment) {
        return Mono.fromCallable(() -> 
            circuitBreaker.executeSupplier(() -> client.score(payment))
        )
        .onErrorResume(CallNotPermittedException.class, e -> {
            // Circuit abierto ‚Üí Fallback
            return Mono.just(RiskScore.defaultSafe());
        });
    }
}
```

**Configuraci√≥n por Servicio**:

| Servicio | Failure Rate | Wait Duration | Fallback |
|----------|--------------|---------------|----------|
| Fraud | 50% | 30s | RiskScore(50, MANUAL_REVIEW) |
| FX | 60% | 60s | Cached rate (max 10 min old) |
| Clearing | 40% | 120s | Retry queue |

---

### Patr√≥n 7: Bulkhead

**WHY** (Contenci√≥n de Recursos):
- **Agotamiento de Thread Pools**: Sistema actual utiliza un pool global de 200 threads sin segregaci√≥n, donde operaciones lentas de clearing internacional (30s promedio) agotan recursos afectando operaciones cr√≠ticas de consulta
- **Impacto en SLA**: Operaciones r√°pidas de consulta (objetivo p99 < 50ms) se degradan significativamente por contenci√≥n con operaciones lentas de clearing
- **Aislamiento de Fallos**: Segregar pools de threads por tipo de operaci√≥n garantiza que latencias en red externa (SWIFT, timeout 30s) no afecten experiencia de usuario en operaciones locales

**HOW**:

```java
// Thread pools separados
@Configuration
public class BulkheadConfig {
    
    @Bean("fraudPool")
    public Executor fraudThreadPool() {
        return new ThreadPoolTaskExecutor() {{
            setCorePoolSize(5);
            setMaxPoolSize(10);
            setQueueCapacity(50);
            setThreadNamePrefix("fraud-");
        }};
    }
    
    @Bean("clearingPool")
    public Executor clearingThreadPool() {
        return new ThreadPoolTaskExecutor() {{
            setCorePoolSize(10);
            setMaxPoolSize(20);
            setQueueCapacity(100);
            setThreadNamePrefix("clearing-");
        }};
    }
}

// Uso
@Service
public class PaymentService {
    
    @Async("fraudPool")
    public CompletableFuture<RiskScore> callFraud(PaymentOrder payment) {
        // Ejecuta en pool dedicado
    }
    
    @Async("clearingPool")
    public CompletableFuture<Void> callClearing(PaymentOrder payment) {
        // Ejecuta en pool separado
    }
}
```

---

## üö´ Patrones Evaluados y Descartados

### 1. Two-Phase Commit (2PC)

**WHY se evalu√≥**: Garantizar consistencia ACID en transacciones distribuidas

**WHY se descart√≥**:
- ‚ùå Bloquea recursos (locks distribuidos)
- ‚ùå No tolera fallos parciales (timeout ‚Üí rollback global)
- ‚ùå Latencia inaceptable (>500ms para commit cross-DB)

**Alternativa elegida**: **Saga Pattern** con compensaci√≥n

---

### 2. Shared Database

**WHY se evalu√≥**: Simplificar arquitectura (1 DB para todos los servicios)

**WHY se descart√≥**:
- ‚ùå Acoplamiento de esquema (cambio en Payment afecta a Ledger)
- ‚ùå No escala (contenci√≥n en tablas compartidas)
- ‚ùå Viola principio de Bounded Context (DDD)

**Alternativa elegida**: **Database per Service** + Event-Driven integration

---

### 3. REST Polling para Eventos

**WHY se evalu√≥**: Alternativa a Kafka (cliente consulta GET /events cada X segundos)

**WHY se descart√≥**:
- ‚ùå Latencia alta (lag de hasta X segundos)
- ‚ùå Carga innecesaria (90% de polls sin datos nuevos)
- ‚ùå No escala (10K clientes √ó 1 req/s = 10K req/s)

**Alternativa elegida**: **WebSockets** (push en tiempo real) + **Kafka** (server-to-server)

---

## üìä Matriz de Decisi√≥n de Patrones

| Quality Attribute | Contexto del Sistema Actual | Patr√≥n Arquitect√≥nico | Alternativa Descartada | Impacto Medible en el Negocio |
|-------------------|----------------------------|----------------------|----------------------|--------------------------------|
| **Disponibilidad Continua** | Sistema cr√≠tico 24/7 procesando 8.5M transacciones/mes sin ventanas de mantenimiento | **Strangler Fig Pattern** | Big Bang Migration | Migraci√≥n incremental 10%‚Üí70%‚Üí100% en 12 meses sin interrupci√≥n de servicio |
| **Calidad de C√≥digo** | Entidad Account.java con 200+ campos que viola principios SOLID | **Anti-Corruption Layer** | Shared Domain Model | Aislamiento completo: 0% de clases Legacy en nueva arquitectura |
| **Integridad de Datos** | Reconciliaci√≥n manual nocturna con ventana de 6 horas genera inconsistencias | **Change Data Capture** | Dual-Write Pattern | Sincronizaci√≥n en tiempo real (lag < 2s), elimina ventana de 6 horas |
| **Performance** | 90% del tr√°fico son consultas que compiten con escrituras por recursos | **CQRS Pattern** | Single Database Model | Read queries p99 < 50ms, Write commands p99 < 100ms |
| **Auditor√≠a Regulatoria** | Trazabilidad limitada en sistema actual (PCI-DSS, GDPR) | **Event Sourcing** | Traditional Audit Tables | 100% trazabilidad + capacidad de reconstrucci√≥n hist√≥rica para compliance |
| **Consistencia Distribuida** | Pago internacional coordina 5 servicios sin gesti√≥n de fallos | **Saga Pattern (Temporal.io)** | Two-Phase Commit (2PC) | Compensaci√≥n autom√°tica sin bloqueos (vs. 30s locks actuales) |
| **Tolerancia a Fallos** | Ca√≠da de ML Fraud detiene procesamiento completo del sistema | **Circuit Breaker Pattern** | Infinite Retry | Degradaci√≥n controlada: fallback a reglas permite continuar operaci√≥n |
| **Aislamiento de Recursos** | Pool global de threads: operaciones SWIFT lentas (30s) bloquean consultas | **Bulkhead Pattern** | Single Thread Pool | Thread pools segregados: clearing no afecta SLA de consultas (50ms p99) |
| **Agilidad Organizacional** | Time-to-Market actual de 4 meses por acoplamiento monol√≠tico | **Microservices Architecture** | Modular Monolith | Despliegues independientes por equipo: reducci√≥n a 2 semanas |

---

## üé® Diagrama de Integraci√≥n de Patrones

```mermaid
graph TB
    subgraph Payment["Payment Service"]
        CMD[CQRS Command Handler]
        QUERY[CQRS Query Handler]
        SAGA[Saga Orchestrator<br/>Temporal.io]
        CB[Circuit Breaker<br/>Resilience4j]
    end
    
    subgraph Legacy["Legacy Integration"]
        ACL[Anti-Corruption Layer<br/>Legacy Facade]
        CDC[CDC Adapter<br/>Debezium]
    end
    
    subgraph Ledger["Ledger Service"]
        ES[Event Sourcing]
        EVENTSTORE[Event Store<br/>TimescaleDB]
    end
    
    subgraph Data["Data Layer"]
        PG[(PostgreSQL<br/>Write Model)]
        ELASTIC[(Elasticsearch<br/>Read Model)]
        KAFKA[Kafka<br/>Event Bus]
        ORACLE[(Legacy Oracle)]
    end
    
    CMD -->|1-Ejecuta pasos| SAGA
    SAGA -->|2-Protege llamadas| CB
    CB -->|3-Publica eventos| KAFKA
    QUERY -->|4-Lee proyecciones| ELASTIC
    
    ES -->|5-Persiste eventos| EVENTSTORE
    EVENTSTORE -->|6-Stream infinito| KAFKA
    KAFKA -->|7-Proyecta read model| ELASTIC
    
    CDC -->|8-Captura cambios| ORACLE
    CDC -->|9-Sincroniza| KAFKA
    KAFKA -->|10-Replica| PG
    
    SAGA -->|11-Traduce modelos| ACL
    ACL -->|12-Interact√∫a| ORACLE
    
    style Payment fill:#e1f5ff
    style Legacy fill:#fff4e1
    style Ledger fill:#e8f5e9
    style Data fill:#f3e5f5
```

---

**Fecha de Propuesta**: 24 de diciembre de 2025
