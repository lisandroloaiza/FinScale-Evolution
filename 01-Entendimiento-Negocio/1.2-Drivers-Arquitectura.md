# 1.2 Drivers de Arquitectura

> **Objetivo**: Traducir los objetivos estrat√©gicos de negocio en drivers de arquitectura concretos y medibles.  
> **Metodolog√≠a**: WhyDD - "El Why del Negocio al How T√©cnico"

---

## üéØ Objetivos Estrat√©gicos de FinScale

Derivados del an√°lisis de Domain Storytelling (ver 1.1-Domain-Storytelling.md):

| ID | Objetivo Estrat√©gico | Origen | Driver Relacionado |
|----|---------------------|--------|--------------------|
| OE-1 | Escalar de 2,000 TPS a 1,000,000 TPS | Dolor: Sticky Sessions, Secuencias Globales | Escalabilidad |
| OE-2 | Eliminar ventana de mantenimiento de 6 horas (operar 24/7) | Dolor: Batch Reconciliaci√≥n bloqueante | Disponibilidad |
| OE-3 | Reducir Time-to-Market de 4 meses a 2 semanas | Dolor: God Classes, Monolito acoplado | Time-to-Market |
| OE-4 | Aislar fallos (un m√≥dulo ca√≠do no tumba pagos) | Dolor: M√≥dulo fraude tumba pagos | Resiliencia |
| OE-5 | Migrar l√≥gica de 40% PL/SQL a servicios cloud-native | Dolor: L√≥gica atrapada en stored procedures | Modernizaci√≥n |
| OE-6 | Cumplir con PCI-DSS y GDPR en todas las operaciones | Requerimiento regulatorio continuo | Cumplimiento |

---

## üìã Matriz de Drivers de Arquitectura

### Estructura del Driver

Cada driver sigue la plantilla WhyDD:

```
WHY (Negocio) ‚Üí WHAT (Driver T√©cnico) ‚Üí HOW (M√©tricas)
```

---

## 1Ô∏è‚É£ Escalabilidad Extrema

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-1 - Escalar de 2,000 TPS a 1,000,000 TPS  
**Dolores Actuales** (ver 1.1-Domain-Storytelling.md):
- **Sticky Sessions**: HttpSession en RAM impide escalado horizontal din√°mico
- **Secuencias Globales**: IDs √∫nicos centralizados en Oracle son cuello de botella
- **Bloqueos en BD**: Locks de escritura impiden escalar m√≥dulos individualmente
- **Conexiones Stateful**: TCP/IP stateful para SWIFT dificulta escalado

**Impacto de NO Resolver**:
- Sistema colapsa en picos de demanda (imposibilidad de procesar volumen requerido)
- Incapacidad de competir con neobancos cloud-native
- Imposibilidad de crecer en mercados con alto volumen transaccional

### WHAT (Driver de Arquitectura)

**Driver**: La arquitectura debe soportar escalamiento horizontal el√°stico de 500x en throughput transaccional sin degradaci√≥n de latencia.

**Escenarios de Calidad (QAS - Quality Attribute Scenarios)**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| 1,000,000 TPS de pago | Evento masivo de mercadeo | M√≥dulo Pagos | Operaci√≥n normal | El sistema escala horizontalmente | Latencia P99 < 200ms |
| Escalar de 2,000 TPS a 1,000,000 TPS (500x) | Crecimiento demanda eventos masivos | Toda la plataforma | Pico de carga | Auto-scaling de contenedores | Tiempo de escala < 30s |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline Actual | Target | Medici√≥n |
|---------|-----------------|--------|----------|
| **Throughput** | 2,000 TPS | 1,000,000 TPS | Prometheus (rate) |
| **Latencia P50** | 400ms | 50ms | APM (New Relic/Datadog) |
| **Latencia P99** | 1,200ms | 200ms | APM |
| **Tiempo de Auto-Scaling** | N/A (manual) | < 30s | Kubernetes HPA metrics |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Reactive Programming** (Spring WebFlux): Non-blocking I/O
- ‚úÖ **Horizontal Scaling**: Stateless microservices en Kubernetes
- ‚úÖ **Event-Driven**: Desacoplamiento con Kafka/Pulsar
- ‚úÖ **Caching Distribuido**: Redis para sesiones y datos de referencia
- ‚úÖ **Database Sharding**: Particionar por regi√≥n geogr√°fica

---

## 2Ô∏è‚É£ Disponibilidad Continua (24/7)

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-2 - Eliminar ventana de mantenimiento de 6 horas  
**Dolores Actuales** (ver 1.1-Domain-Storytelling.md):
- **Ventana de Mantenimiento Cr√≠tica**: Batch de reconciliaci√≥n (00:00-06:00 UTC) bloquea BD en READ-ONLY
- **Sistema no opera 24/7**: 6 horas diarias de indisponibilidad para transacciones
- **Despliegues de 6 horas**: God Classes monol√≠ticas requieren ventanas extensas

**Impacto de NO Resolver**:
- P√©rdida de transacciones durante ventana de mantenimiento
- Incumplimiento de operaci√≥n continua requerida para mercados globales
- Imposibilidad de desplegar mejoras sin afectar operaci√≥n

### WHAT (Driver de Arquitectura)

**Driver**: La arquitectura debe garantizar operaci√≥n continua 24/7/365 eliminando ventanas de mantenimiento programadas.

**Escenarios de Calidad**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| Fallo de zona cloud | AWS AZ-1 cae | Toda la plataforma | Operaci√≥n normal | Failover autom√°tico a AZ-2 | RTO < 30s |
| Despliegue de nueva versi√≥n | DevOps | Microservicio Pagos | Operaci√≥n normal | Zero-downtime deploy | 0% error rate |
| Fallo de base de datos | Oracle crash | Ledger | Operaci√≥n degradada | Replica promovida a primaria | RPO < 1s |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline Actual | Target | Medici√≥n |
|---------|-----------------|--------|----------|
| **Ventana Mantenimiento** | 6 horas/d√≠a | 0 horas (24/7) | Deployment tracking |
| **Deployment Frequency** | 1 vez/mes (6h ventana) | M√∫ltiples/d√≠a (zero-downtime) | CI/CD metrics |
| **MTTR (Mean Time To Recovery)** | Alto (monolito) | < 5 minutos (microservicios) | Incident tracking |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Multi-AZ Deployment**: R√©plicas en 3 zonas de disponibilidad
- ‚úÖ **Circuit Breaker**: Aislamiento de fallos (Resilience4j)
- ‚úÖ **Health Checks**: Liveness/Readiness probes en Kubernetes
- ‚úÖ **Blue-Green Deployment**: Zero-downtime releases
- ‚úÖ **Database Replication**: Multi-master o active-passive con lag < 1s

---

## 3Ô∏è‚É£ Resiliencia y Aislamiento de Fallos

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-4 - Aislar fallos entre m√≥dulos  
**Dolores Actuales** (ver 1.1-Domain-Storytelling.md):
- **Acoplamiento Monol√≠tico**: M√≥dulo de fraude tumba el de pagos cuando falla
- **Bloqueos en BD**: Locks en Oracle afectan a todos los m√≥dulos
- **Shared Database**: Sistemas sat√©lites acceden directo a CORE_SCHEMA, cambios rompen integraciones

**Impacto de NO Resolver**:
- Downtime en cadena (un m√≥dulo no cr√≠tico afecta procesos cr√≠ticos)
- Imposibilidad de cumplir SLA de pagos (99.999%)
- P√©rdida de confianza de reguladores y partners bancarios

### WHAT (Driver de Arquitectura)

**Driver**: Un fallo catastr√≥fico en un subsistema no cr√≠tico (ej. Notificaciones, Reportes) NO debe afectar subsistemas cr√≠ticos (Pagos, Ledger, Fraude).

**Escenarios de Calidad**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| Servicio Notificaciones cae (OOM) | Bug en c√≥digo | Microservicio Notificaciones | Operaci√≥n normal | Pagos contin√∫an sin afectaci√≥n | 0% impacto en TPS de Pagos |
| Proveedor KYC (Jumio) timeout | Red externa | Servicio Onboarding | Degradaci√≥n parcial | Onboarding en modo manual | Pagos existentes 100% operativos |
| BD de Reportes saturada | Query pesado | Base datos Analytics | Operaci√≥n normal | Circuit breaker abierto | Ledger no afectado |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline | Target | Medici√≥n |
|---------|----------|--------|----------|
| **Blast Radius** (radio de impacto) | 100% (todo cae) | < 10% (subsistema aislado) | Dependency mapping |
| **Circuit Breaker Activations** | N/A | > 0 (est√° funcionando) | Resilience4j metrics |
| **Graceful Degradation** | 0% | 100% de features no cr√≠ticas | Feature flags |
| **Cascade Failure Rate** | 80% | < 5% | Error correlation analysis |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Bulkhead Pattern**: Aislamiento de recursos (thread pools separados)
- ‚úÖ **Circuit Breaker**: Corte r√°pido de dependencias fallidas
- ‚úÖ **Timeout & Retry con Backoff**: Prevenir bloqueos indefinidos
- ‚úÖ **Async Communication**: Eventos en lugar de llamadas s√≠ncronas
- ‚úÖ **Feature Flags**: Desactivar funcionalidades no cr√≠ticas din√°micamente

---

## 4Ô∏è‚É£ Modernizaci√≥n Tecnol√≥gica (Cloud Native)

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-5 - Migrar 40% l√≥gica PL/SQL a cloud-native  
**Dolores Actuales** (ver 1.1-Domain-Storytelling.md):
- **L√≥gica atrapada en PL/SQL**: 40% de reglas de negocio en stored procedures Oracle
- **God Classes**: TransactionManager.java con 15K l√≠neas, imposible desplegar m√≥dulos aislados
- **Time-to-Market de 4 meses**: Cambios requieren DBA, no DevOps
- **HSM F√≠sico on-premise**: Dificulta migraci√≥n a Cloud

**Impacto de NO Resolver**:
- Imposibilidad de migrar m√≥dulos de forma independiente
- Incapacidad de competir con neobancos cloud-native
- Deuda t√©cnica que paraliza innovaci√≥n

### WHAT (Driver de Arquitectura)

**Driver**: Migrar a stack Cloud Native (Spring Boot Reactive, Kubernetes, Managed Services) con infraestructura el√°stica y pago por uso.

**Escenarios de Calidad**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| Lanzamiento GlobalLedger | Producto | Nuevo m√≥dulo | Desarrollo | Deploy independiente sin afectar m√≥dulos existentes | Time-to-Market < 2 semanas |
| Migraci√≥n m√≥dulo Fraude de PL/SQL a Java | Modernizaci√≥n t√©cnica | M√≥dulo Fraude | Producci√≥n | Extracci√≥n sin afectar Pagos | < 1 mes (vs 4 meses actual) |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline Actual | Target | Medici√≥n |
|---------|-----------------|--------|----------|
| **L√≥gica en PL/SQL** | 40% | 0% (migrado a servicios) | Code analysis |
| **Time-to-Market** | 4 meses | 2 semanas | DORA metrics |
| **Tama√±o God Classes** | 15K l√≠neas (TransactionManager) | < 500 l√≠neas/clase | SonarQube |
| **Deployment Frequency** | 1 vez/mes | M√∫ltiples/d√≠a | CI/CD pipeline |
| **Lead Time for Changes** | 4 meses | < 1 semana | DORA metrics |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Containerizaci√≥n**: Docker + Kubernetes
- ‚úÖ **Reactive Stack**: Spring Boot 3 + WebFlux + R2DBC
- ‚úÖ **Managed Services**: RDS, ElastiCache, Kafka (MSK), S3
- ‚úÖ **Infrastructure as Code**: Terraform / Pulumi
- ‚úÖ **Observability**: OpenTelemetry + Prometheus + Grafana

---

## 5Ô∏è‚É£ Cumplimiento Normativo (PCI-DSS, GDPR)

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-6 - Cumplir con PCI-DSS y GDPR  
**Dolores Actuales**:
- **Falta de Audit Trail**: Sin trazabilidad completa de acceso a datos sensibles
- **Shared Database**: Accesos directos a CORE_SCHEMA sin control granular
- **Sistemas Legacy**: Dificultad para implementar controles requeridos por reguladores

**Impacto de NO Resolver**:
- Riesgo de multas regulatorias y p√©rdida de licencias
- Imposibilidad de operar en jurisdicciones reguladas
- P√©rdida de confianza de reguladores y partners bancarios

### WHAT (Driver de Arquitectura)

**Driver**: La arquitectura debe garantizar trazabilidad total (audit trail), encriptaci√≥n end-to-end y segregaci√≥n de datos sensibles seg√∫n PCI-DSS y GDPR.

**Escenarios de Calidad**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| Auditor solicita "¬øQui√©n accedi√≥ al PAN de tarjeta X?" | Regulador | Audit logs | Auditor√≠a | Sistema retorna log completo | < 5 segundos |
| Usuario ejerce "Derecho al Olvido" (GDPR) | Cliente UE | Todos los sistemas | Operaci√≥n normal | Borrado completo en 30 d√≠as | 100% compliance |
| Detecci√≥n de acceso no autorizado | SIEM | Base de datos | Operaci√≥n normal | Alerta + bloqueo autom√°tico | < 1 segundo |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline | Target | Medici√≥n |
|---------|----------|--------|----------|
| **Audit Coverage** | 40% de transacciones | 100% | Audit log volume |
| **Data Encryption at Rest** | 30% | 100% (PCI Level 1) | Compliance scan |
| **GDPR Compliance Score** | 60% | 100% | Privacy audit |
| **Time to Audit Report** | 6 meses | 1 d√≠a (automatizado) | Compliance dashboard |
| **Sensitive Data Exposure** | 5 incidentes/a√±o | 0 | Security monitoring |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Event Sourcing**: Audit trail inmutable
- ‚úÖ **Tokenization**: PCI-compliant para PANs de tarjetas
- ‚úÖ **Encryption**: TLS 1.3 + AES-256 at rest
- ‚úÖ **RBAC (Role-Based Access Control)**: Segregaci√≥n de acceso
- ‚úÖ **Data Masking**: PII ofuscado en logs y entornos no-productivos

---

## 6Ô∏è‚É£ Time-to-Market Acelerado

### WHY (Raz√≥n de Negocio)

**Objetivo Estrat√©gico**: OE-3 - Reducir Time-to-Market de 4 meses a 2 semanas  
**Dolores Actuales** (ver 1.1-Domain-Storytelling.md):
- **God Classes**: TransactionManager.java (15K l√≠neas) con acoplamiento c√≠clico impide despliegues modulares
- **Despliegues de 6 horas**: Requieren ventana extensa por riesgo de afectar todo el sistema
- **40% l√≥gica en PL/SQL**: Cambios requieren DBA, no DevOps (aumenta time-to-market)

**Impacto de NO Resolver**:
- Incapacidad de lanzar features r√°pidamente
- P√©rdida de competitividad frente a neobancos √°giles
- Equipos de desarrollo frustrados por procesos lentos

### WHAT (Driver de Arquitectura)

**Driver**: La arquitectura debe permitir despliegues independientes de componentes con ciclos de release semanales.

**Escenarios de Calidad**

| Est√≠mulo | Fuente | Artefacto | Entorno | Respuesta | Medida |
|----------|--------|-----------|---------|-----------|--------|
| Nuevo pa√≠s (Brasil - PIX) | Negocio | M√≥dulo de Pagos | Desarrollo | Deploy sin afectar otros pa√≠ses | < 2 semanas |
| Hotfix cr√≠tico en Fraude | Bug en producci√≥n | Microservicio Fraude | Producci√≥n | Deploy aislado | < 2 horas |

### HOW (M√©tricas de √âxito)

| M√©trica | Baseline | Target | Medici√≥n |
|---------|----------|--------|----------|
| **Time-to-Market** | 4 meses | 2 semanas | Feature tracking |
| **Deployment Frequency** | 1/mes | 10/d√≠a | DORA metrics |
| **Change Failure Rate** | 30% | < 5% | CI/CD stats |
| **MTTR (bugs)** | 8 horas | 1 hora | Incident management |

### T√°cticas de Arquitectura Propuestas

- ‚úÖ **Microservices**: Bounded contexts independientes
- ‚úÖ **API Gateway**: Versionamiento de APIs
- ‚úÖ **Strangler Fig**: Migraci√≥n incremental sin Big Bang
- ‚úÖ **CI/CD Pipelines**: Automated testing + canary deployments

---

## üìä Matriz de Priorizaci√≥n de Drivers

| Driver | Impacto Negocio | Complejidad T√©cnica | Prioridad | Fase |
|--------|-----------------|---------------------|-----------|------|
| **Escalabilidad** | üî¥ Cr√≠tico | üü° Alta | P0 | Fase 1 |
| **Disponibilidad** | üî¥ Cr√≠tico | üü° Alta | P0 | Fase 1 |
| **Resiliencia** | üî¥ Cr√≠tico | üü† Media | P0 | Fase 1 |
| **Modernizaci√≥n** | üü° Alto | üî¥ Muy Alta | P1 | Fases 1-3 |
| **Cumplimiento** | üî¥ Cr√≠tico | üü† Media | P0 | Continuo |
| **Time-to-Market** | üü° Alto | üü° Alta | P1 | Fase 2 |

---

## üé≠ Trade-offs Arquitect√≥nicos (Anticipados)

| Trade-off | Decisi√≥n | Justificaci√≥n |
|-----------|----------|---------------|
| **Consistencia vs. Disponibilidad (CAP)** | Disponibilidad + Consistencia Eventual | Para Notificaciones/Reportes. Consistencia Fuerte solo en Saldos/Ledger. |
| **Latencia vs. Throughput** | Optimizar Throughput | El negocio tolera 200ms de latencia si procesa 1M TPS. |
| **Costo vs. Resiliencia** | Invertir en Multi-AZ | El impacto de downtime en operaci√≥n 24/7 justifica infraestructura redundante. |
| **Complejidad vs. Flexibilidad** | Microservicios | Aceptar complejidad operacional (observability, distributed tracing) a cambio de agilidad. |

---

**Pr√≥ximo Paso**: ‚Üí `1.3-Business-Capabilities.md` para mapear capacidades de negocio afectadas.

---

**√öltima actualizaci√≥n**: 7 de diciembre de 2025
